# LOFT Configuration
# Copy this file to .env and fill in your values

# ============================================
# LLM API Keys
# ============================================
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Optional: OpenAI API key for secondary LLM support
# Get your API key from: https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key-here

# ============================================
# LLM Configuration
# ============================================
# Provider: "anthropic" or "openai"
LLM_PROVIDER=anthropic

# Model selection
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-haiku-20240307
# OpenAI: gpt-4, gpt-3.5-turbo
LLM_MODEL=claude-3-5-sonnet-20241022

# Temperature for LLM sampling (0.0-2.0)
LLM_TEMPERATURE=0.7

# Maximum tokens in LLM response
LLM_MAX_TOKENS=4096

# ============================================
# Logging
# ============================================
# Log level: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================
# ASP Configuration
# ============================================
# Directory containing ASP program files
ASP_PROGRAMS_DIR=programs

# Maximum number of answer sets to compute
ASP_MAX_ANSWER_SETS=10

# ============================================
# Validation Thresholds
# ============================================
# Confidence thresholds for each stratification layer (0.0-1.0)

# Strategic layer: high-level reasoning patterns (slow change)
CONFIDENCE_THRESHOLD_STRATEGIC=0.9

# Tactical layer: domain-specific rules (frequent updates)
CONFIDENCE_THRESHOLD_TACTICAL=0.8

# Operational layer: immediate heuristics (rapid adaptation)
CONFIDENCE_THRESHOLD_OPERATIONAL=0.6

# Note: Constitutional layer is always 1.0 (requires human approval)
